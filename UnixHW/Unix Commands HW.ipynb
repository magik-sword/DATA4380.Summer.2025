{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85bc178",
   "metadata": {},
   "source": [
    "# Unix Commands Homework - Diego Maldonado #1002096994\n",
    "After completing all the previous set up, I copied the 'zip_files.zip' folder containing all the kaggle datasets from my Windows downloads folder to my Ubuntu home directory using the command:\n",
    "- cp /mnt/c/Users/dm400/Downloads/zip_files.zip /home/diegom04 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbacc185",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "The first unzip command will automatically create a directory named 'zip_files' with the dataset zip files in it. Then, enter the new directory containing the zipfiles and unzip them all. Now all the CSV files are accessible.\n",
    "- unzip zip_files.zip\n",
    "- cd zip_files\n",
    "- unzip '*.zip'\n",
    "\n",
    "## Exercise 2\n",
    "First, select only the header of the original dataset and then input it into three new CSV files. \n",
    "- head -n 1 diabetes_prediction_dataset.csv > diabetes_prediction_dataset1.csv\n",
    "- head -n 1 diabetes_prediction_dataset.csv > diabetes_prediction_dataset2.csv\n",
    "- head -n 1 diabetes_prediction_dataset.csv > diabetes_prediction_dataset3.csv\n",
    "\n",
    "The command below shows there are are 100,001 total lines in the CSV file, one header and 100k entries. So, the first two CSV files will hold 33,333 entries and the third will hold 33,334 entries.\n",
    "- wc -l diabetes_prediction_dataset.csv\n",
    "\n",
    "Now, we'll be selecting various parts of the original file and appending it to each of the new CSV files. For example, the first command will select the first 33,334 entries in the file, and the tail command following it will only append the last 33,333 lines in the selected head entries to the new file, leaving the header out of it.\n",
    "- cat diabetes_prediction_dataset.csv | head -33334 | tail -33333 >> diabetes_prediction_dataset1.csv\n",
    "- cat diabetes_prediction_dataset.csv | head -66667 | tail -33333 >> diabetes_prediction_dataset2.csv\n",
    "- cat diabetes_prediction_dataset.csv | head -100001 | tail -33334 >> diabetes_prediction_dataset3.csv\n",
    "\n",
    "## Exercise 3\n",
    "Select the header of the original CSV file and output it to two new files.\n",
    "- head -n 1 Heart_Disease_Prediction.csv > Heart_Disease_Prediction_Prescence.csv\n",
    "- head -n 1 Heart_Disease_Prediction.csv > Heart_Disease_Prediction_Abscence.csv\n",
    "\n",
    "Select the entries that contain the 'Presence' or 'Absence' label and append them to the appropiate file. I'll use -i in the command as well to ensure we ignore case. \n",
    "- grep -i \"Presence\" Heart_Disease_Prediction.csv >> Heart_Disease_Prediction_Presence.csv\n",
    "- grep -i \"Absence\" Heart_Disease_Prediction.csv >> Heart_Disease_Prediction_Absence.csv\n",
    "\n",
    "## Exercise 4\n",
    "First, we need to find out the number of cars in the dataset. There are a total of 2841 lines, so there are 2840 entries. Also taking a look at the first few entries of the dataset we'll be searching for the phrase 'No accidents reported.'\n",
    "- head car_web_scraped_dataset.csv\n",
    "- wc -l car_web_scraped_dataset.csv\n",
    "\n",
    "There are a total of 2,223 entries that have no accidents reported.\n",
    "- grep -w \"No accidents reported\" car_web_scraped_dataset.csv | wc -l\n",
    "\n",
    "2,223 / 2,840 = 0.7827, so about 78.27% of the cars in the dataset have no accidents.\n",
    "\n",
    "## Exercise 5\n",
    "The -e allows multiple sed commands to be executed. I also ensured that 'furnished' was replaced last so it didn't cause unintended consequences such as only replacing the furnished part in semi-furnished. All the resulting edits are then appended to a new CSV file.\n",
    "- sed -e 's/yes/1/g' -e 's/no/0/g' -e 's/unfurnished/0/g' -e 's/semi-furnished/2/g' -e 's/furnished/1/g' Housing.csv >> Housing_edited.csv\n",
    "\n",
    "## Exercise 6\n",
    "The command cuts the first field (CustomerID) and redirects the remaining field that weren't cut into a new CSV file.\n",
    "- cut --complement -d \",\" -f 1 Mall_Customers.csv > Mall_Customers_New.csv\n",
    "\n",
    "## Exercise 7\n",
    "In some of the entries in the file it shows a range of scores (eg. 46.7-49.1) instead of a single number, and the dash between them is preventing the sum from being calculated due to it not being an ASCII character. So, we'll have to convert it to an appropiate ASCII character before performing the actual calculations.\n",
    "- sed 's/â€“/-/g' 'world all university rank and rank score.csv' > clean_scores.csv\n",
    "\n",
    "The commands selects only the entries after the header and only fields 5-8. It then converts the commas into plus signs and pipes it to a basic calculator to perform addition. The final sums are then inputted into a new CSV file.\n",
    "- tail -910 clean_scores.csv | cut -d \",\" -f 5-8 | tr \",\" \"+\" | bc > university_score_sums.csv\n",
    "\n",
    "## Exercise 8\n",
    "Designate the comma as a delimiter, sort the data numerically by the third field (Age column), and output the new sorted data into a seperate CSV file.\n",
    "- sort -t \",\" -k3 -n  'cancer patient data sets.csv' > sorted_cancer_patients.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
